{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import sys\n",
        "import pandas as pd \n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "df_posts = pd.read_csv(\"../DATA/cleaned_posts.csv\")\n",
        "df_comments = pd.read_csv(\"../DATA/cleaned_comments.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['selftext', 'created_utc', 'ups', 'subreddit', 'link_flair_text',\n",
            "       'title', 'text'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "#Fixing typing from read_csv\n",
        "df_posts['text'] = df_posts['text'].astype(str)\n",
        "df_comments['text'] = df_comments['text'].astype(str)\n",
        "print(df_posts.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to\n",
            "[nltk_data]     C:\\Users\\brian\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Import and download pretrained VADER model\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "import nltk\n",
        "nltk.download('vader_lexicon')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def add_sentiment_scores(df):\n",
        "    # Initialize VADER SentimentIntensityAnalyzer\n",
        "    sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "    #Ensure typing, removing empty strings\n",
        "    df['text'] = df['text'].astype(str).str.strip()\n",
        "\n",
        "    # Calculate sentiment scores and add to dataset\n",
        "    df['compound_sentiment_score'] = df['text'].apply(lambda x: sia.polarity_scores(x)['compound'])\n",
        "    df['positive_sentiment_score'] = df['text'].apply(lambda x: sia.polarity_scores(x)['pos'])\n",
        "    df['negative_sentiment_score'] = df['text'].apply(lambda x: sia.polarity_scores(x)['neg'])\n",
        "    df['neutral_sentiment_score'] = df['text'].apply(lambda x: sia.polarity_scores(x)['neu'])\n",
        "    return df\n",
        "\n",
        "#Calculate scores for both datasets\n",
        "posts_scored = add_sentiment_scores(df_posts)\n",
        "comments_scored = add_sentiment_scores(df_comments)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def filter_by_keyword(df, keyword):\n",
        "    # Filter for posts/comments that contain the specified keyword (case insensitive)\n",
        "    return df[df['text'].str.contains(keyword, case=False, na=False)]\n",
        "\n",
        "posts_filtered = filter_by_keyword(posts_scored, 'biden')\n",
        "comments_filtered = filter_by_keyword(comments_scored, 'biden')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>created_utc</th>\n",
              "      <th>ups</th>\n",
              "      <th>compound_sentiment_score</th>\n",
              "      <th>positive_sentiment_score</th>\n",
              "      <th>negative_sentiment_score</th>\n",
              "      <th>neutral_sentiment_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>9.890000e+02</td>\n",
              "      <td>989.000000</td>\n",
              "      <td>989.000000</td>\n",
              "      <td>989.000000</td>\n",
              "      <td>989.000000</td>\n",
              "      <td>989.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1.721478e+09</td>\n",
              "      <td>84.675430</td>\n",
              "      <td>0.047356</td>\n",
              "      <td>0.082413</td>\n",
              "      <td>0.076390</td>\n",
              "      <td>0.841185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2.658780e+05</td>\n",
              "      <td>325.855018</td>\n",
              "      <td>0.429822</td>\n",
              "      <td>0.117014</td>\n",
              "      <td>0.117899</td>\n",
              "      <td>0.153137</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.720915e+09</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.997600</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.244000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.721266e+09</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.202300</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.743000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.721521e+09</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.849000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.721660e+09</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>0.340000</td>\n",
              "      <td>0.151000</td>\n",
              "      <td>0.140000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.722113e+09</td>\n",
              "      <td>4988.000000</td>\n",
              "      <td>0.999500</td>\n",
              "      <td>0.697000</td>\n",
              "      <td>0.660000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        created_utc          ups  compound_sentiment_score  \\\n",
              "count  9.890000e+02   989.000000                989.000000   \n",
              "mean   1.721478e+09    84.675430                  0.047356   \n",
              "std    2.658780e+05   325.855018                  0.429822   \n",
              "min    1.720915e+09     0.000000                 -0.997600   \n",
              "25%    1.721266e+09     1.000000                 -0.202300   \n",
              "50%    1.721521e+09     1.000000                  0.000000   \n",
              "75%    1.721660e+09    15.000000                  0.340000   \n",
              "max    1.722113e+09  4988.000000                  0.999500   \n",
              "\n",
              "       positive_sentiment_score  negative_sentiment_score  \\\n",
              "count                989.000000                989.000000   \n",
              "mean                   0.082413                  0.076390   \n",
              "std                    0.117014                  0.117899   \n",
              "min                    0.000000                  0.000000   \n",
              "25%                    0.000000                  0.000000   \n",
              "50%                    0.000000                  0.000000   \n",
              "75%                    0.151000                  0.140000   \n",
              "max                    0.697000                  0.660000   \n",
              "\n",
              "       neutral_sentiment_score  \n",
              "count               989.000000  \n",
              "mean                  0.841185  \n",
              "std                   0.153137  \n",
              "min                   0.244000  \n",
              "25%                   0.743000  \n",
              "50%                   0.849000  \n",
              "75%                   1.000000  \n",
              "max                   1.000000  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "posts_filtered.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>created_utc</th>\n",
              "      <th>ups</th>\n",
              "      <th>compound_sentiment_score</th>\n",
              "      <th>positive_sentiment_score</th>\n",
              "      <th>negative_sentiment_score</th>\n",
              "      <th>neutral_sentiment_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1.093400e+04</td>\n",
              "      <td>10934.000000</td>\n",
              "      <td>10934.000000</td>\n",
              "      <td>10934.000000</td>\n",
              "      <td>10934.000000</td>\n",
              "      <td>10934.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1.721476e+09</td>\n",
              "      <td>8.995336</td>\n",
              "      <td>0.079552</td>\n",
              "      <td>0.107372</td>\n",
              "      <td>0.089781</td>\n",
              "      <td>0.802845</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2.788258e+05</td>\n",
              "      <td>39.755202</td>\n",
              "      <td>0.615735</td>\n",
              "      <td>0.086197</td>\n",
              "      <td>0.079944</td>\n",
              "      <td>0.105864</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.720915e+09</td>\n",
              "      <td>-175.000000</td>\n",
              "      <td>-0.999300</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.240000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.721269e+09</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.476700</td>\n",
              "      <td>0.046000</td>\n",
              "      <td>0.024000</td>\n",
              "      <td>0.739000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.721501e+09</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.064400</td>\n",
              "      <td>0.098000</td>\n",
              "      <td>0.080000</td>\n",
              "      <td>0.804000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.721662e+09</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.652850</td>\n",
              "      <td>0.153000</td>\n",
              "      <td>0.133000</td>\n",
              "      <td>0.870000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.722124e+09</td>\n",
              "      <td>1567.000000</td>\n",
              "      <td>0.999300</td>\n",
              "      <td>0.737000</td>\n",
              "      <td>0.760000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        created_utc           ups  compound_sentiment_score  \\\n",
              "count  1.093400e+04  10934.000000              10934.000000   \n",
              "mean   1.721476e+09      8.995336                  0.079552   \n",
              "std    2.788258e+05     39.755202                  0.615735   \n",
              "min    1.720915e+09   -175.000000                 -0.999300   \n",
              "25%    1.721269e+09      1.000000                 -0.476700   \n",
              "50%    1.721501e+09      2.000000                  0.064400   \n",
              "75%    1.721662e+09      6.000000                  0.652850   \n",
              "max    1.722124e+09   1567.000000                  0.999300   \n",
              "\n",
              "       positive_sentiment_score  negative_sentiment_score  \\\n",
              "count              10934.000000              10934.000000   \n",
              "mean                   0.107372                  0.089781   \n",
              "std                    0.086197                  0.079944   \n",
              "min                    0.000000                  0.000000   \n",
              "25%                    0.046000                  0.024000   \n",
              "50%                    0.098000                  0.080000   \n",
              "75%                    0.153000                  0.133000   \n",
              "max                    0.737000                  0.760000   \n",
              "\n",
              "       neutral_sentiment_score  \n",
              "count             10934.000000  \n",
              "mean                  0.802845  \n",
              "std                   0.105864  \n",
              "min                   0.240000  \n",
              "25%                   0.739000  \n",
              "50%                   0.804000  \n",
              "75%                   0.870000  \n",
              "max                   1.000000  "
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "comments_filtered.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of rows in posts_scored: 6146\n",
            "Number of rows in posts_filtered: 989\n",
            "Number of rows in comments_scored: 80285\n",
            "Number of rows in comments_filtered: 10934\n"
          ]
        }
      ],
      "source": [
        "num_rows = posts_scored.shape[0]\n",
        "print(f'Number of rows in posts_scored: {num_rows}')\n",
        "num_rows = posts_filtered.shape[0]\n",
        "print(f'Number of rows in posts_filtered: {num_rows}')\n",
        "num_rows = comments_scored.shape[0]\n",
        "print(f'Number of rows in comments_scored: {num_rows}')\n",
        "num_rows = comments_filtered.shape[0]\n",
        "print(f'Number of rows in comments_filtered: {num_rows}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>created_utc</th>\n",
              "      <th>ups</th>\n",
              "      <th>compound_sentiment_score</th>\n",
              "      <th>positive_sentiment_score</th>\n",
              "      <th>negative_sentiment_score</th>\n",
              "      <th>neutral_sentiment_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1.093400e+04</td>\n",
              "      <td>10934.000000</td>\n",
              "      <td>10934.000000</td>\n",
              "      <td>10934.000000</td>\n",
              "      <td>10934.000000</td>\n",
              "      <td>10934.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1.721476e+09</td>\n",
              "      <td>8.995336</td>\n",
              "      <td>0.079552</td>\n",
              "      <td>0.107372</td>\n",
              "      <td>0.089781</td>\n",
              "      <td>0.802845</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2.788258e+05</td>\n",
              "      <td>39.755202</td>\n",
              "      <td>0.615735</td>\n",
              "      <td>0.086197</td>\n",
              "      <td>0.079944</td>\n",
              "      <td>0.105864</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.720915e+09</td>\n",
              "      <td>-175.000000</td>\n",
              "      <td>-0.999300</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.240000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.721269e+09</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.476700</td>\n",
              "      <td>0.046000</td>\n",
              "      <td>0.024000</td>\n",
              "      <td>0.739000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.721501e+09</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.064400</td>\n",
              "      <td>0.098000</td>\n",
              "      <td>0.080000</td>\n",
              "      <td>0.804000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.721662e+09</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.652850</td>\n",
              "      <td>0.153000</td>\n",
              "      <td>0.133000</td>\n",
              "      <td>0.870000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.722124e+09</td>\n",
              "      <td>1567.000000</td>\n",
              "      <td>0.999300</td>\n",
              "      <td>0.737000</td>\n",
              "      <td>0.760000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        created_utc           ups  compound_sentiment_score  \\\n",
              "count  1.093400e+04  10934.000000              10934.000000   \n",
              "mean   1.721476e+09      8.995336                  0.079552   \n",
              "std    2.788258e+05     39.755202                  0.615735   \n",
              "min    1.720915e+09   -175.000000                 -0.999300   \n",
              "25%    1.721269e+09      1.000000                 -0.476700   \n",
              "50%    1.721501e+09      2.000000                  0.064400   \n",
              "75%    1.721662e+09      6.000000                  0.652850   \n",
              "max    1.722124e+09   1567.000000                  0.999300   \n",
              "\n",
              "       positive_sentiment_score  negative_sentiment_score  \\\n",
              "count              10934.000000              10934.000000   \n",
              "mean                   0.107372                  0.089781   \n",
              "std                    0.086197                  0.079944   \n",
              "min                    0.000000                  0.000000   \n",
              "25%                    0.046000                  0.024000   \n",
              "50%                    0.098000                  0.080000   \n",
              "75%                    0.153000                  0.133000   \n",
              "max                    0.737000                  0.760000   \n",
              "\n",
              "       neutral_sentiment_score  \n",
              "count             10934.000000  \n",
              "mean                  0.802845  \n",
              "std                   0.105864  \n",
              "min                   0.240000  \n",
              "25%                   0.739000  \n",
              "50%                   0.804000  \n",
              "75%                   0.870000  \n",
              "max                   1.000000  "
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "comments_filtered.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      compound_sentiment_score  positive_sentiment_score  \\\n",
            "3                          0.0                       0.0   \n",
            "4                          0.0                       0.0   \n",
            "5                          0.0                       0.0   \n",
            "6                          0.0                       0.0   \n",
            "7                          0.0                       0.0   \n",
            "...                        ...                       ...   \n",
            "6137                       0.0                       0.0   \n",
            "6140                       0.0                       0.0   \n",
            "6143                       0.0                       0.0   \n",
            "6144                       0.0                       0.0   \n",
            "6145                       0.0                       0.0   \n",
            "\n",
            "      negative_sentiment_score  neutral_sentiment_score  \n",
            "3                          0.0                      1.0  \n",
            "4                          0.0                      1.0  \n",
            "5                          0.0                      1.0  \n",
            "6                          0.0                      1.0  \n",
            "7                          0.0                      1.0  \n",
            "...                        ...                      ...  \n",
            "6137                       0.0                      1.0  \n",
            "6140                       0.0                      1.0  \n",
            "6143                       0.0                      1.0  \n",
            "6144                       0.0                      1.0  \n",
            "6145                       0.0                      1.0  \n",
            "\n",
            "[2497 rows x 4 columns]\n"
          ]
        }
      ],
      "source": [
        "#We did some investigation of some of the \"True neutral\" comments as a score of zero seemed erroneous\n",
        "#These were just posts that were too short to contain any rich semantic information \n",
        "filtered = posts_scored[posts_scored['compound_sentiment_score'] == 0.0]\n",
        "print(filtered[['compound_sentiment_score', 'positive_sentiment_score', 'negative_sentiment_score', 'neutral_sentiment_score']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1721583960\n"
          ]
        }
      ],
      "source": [
        "#first, I'll tackle the posts\n",
        "\n",
        "#so, biden posted his dropping out on twitter at 1:46 pm EST \n",
        "#in UTC, this time is: 1:46 PM - 4 hours = 9:46 PM UTC on July 21.\n",
        "\n",
        "from datetime import datetime\n",
        "import pytz\n",
        "\n",
        "# Define the UTC time for 5:46 PM on July 21, 2023\n",
        "utc_time = datetime(2024, 7, 21, 17, 46, 0, tzinfo=pytz.utc)  # 17:46 is 5:46 PM\n",
        "\n",
        "#now we can get the unix timestamp which is what our data uses to identify when tweets were made\n",
        "unix_timestamp = int(utc_time.timestamp())\n",
        "print(unix_timestamp)\n",
        "#the timestamp for Biden's twitter post is 1721598360. Any UTC below this indicates a tweet\n",
        "#before the announcement, and any UTC above indicates a tweet after the announcement\n",
        "\n",
        "\n",
        "df_before = pd.DataFrame()\n",
        "df_after = pd.DataFrame()\n",
        "\n",
        "def before_after_dropout_dataframes(a_dataframe):\n",
        "    \"\"\"\n",
        "    This function creates two new dataframes each respectively containing posts from before and after Biden's dropout announcement\n",
        "    based on his UTC time of dropout we found already.\n",
        "    \"\"\"\n",
        "    global df_after, df_before\n",
        "\n",
        "    df_before = a_dataframe[a_dataframe[\"created_utc\"] < 1721583960].copy()\n",
        "    df_after = a_dataframe[a_dataframe[\"created_utc\"] >= 1721598360].copy()\n",
        "\n",
        "\n",
        "\n",
        "df_before_dem = pd.DataFrame()\n",
        "df_after_dem = pd.DataFrame()\n",
        "\n",
        "df_before_rep = pd.DataFrame()\n",
        "df_after_rep = pd.DataFrame()\n",
        "\n",
        "df_before_PD = pd.DataFrame()\n",
        "df_after_PD = pd.DataFrame()\n",
        "\n",
        "\n",
        "\n",
        "def seperate_by_party(before_df, after_df):\n",
        "    \"\"\"\n",
        "    This function creates several new dataframes each respectively containing posts from the corresponding subreddits\n",
        "    \"\"\"\n",
        "    global df_before_dem, df_after_dem, df_before_rep, df_after_rep, df_before_PD, df_after_PD\n",
        "\n",
        "    df_before_dem = before_df[before_df[\"subreddit\"] == \"democrats\"].copy()\n",
        "    df_after_dem = after_df[after_df[\"subreddit\"] == \"democrats\"].copy()\n",
        "\n",
        "    df_before_rep = before_df[before_df[\"subreddit\"] == \"Republican\"].copy()\n",
        "    df_after_rep = after_df[after_df[\"subreddit\"] == \"Republican\"].copy()\n",
        "\n",
        "    df_before_PD = before_df[before_df[\"subreddit\"] == \"PoliticalDiscussion\"].copy()\n",
        "    df_after_PD = after_df[after_df[\"subreddit\"] == \"PoliticalDiscussion\"].copy()\n",
        "\n",
        "\n",
        "before_after_dropout_dataframes(posts_filtered) #run this BEFORE seperate_by_party()\n",
        "seperate_by_party(df_before, df_after)\n",
        "\n",
        "\n",
        "def ttest(dataframe1, dataframe2):\n",
        "    \"\"\"A t-test using compound sentiment score to see if the change in sentiment is statistically significant\n",
        "    \"\"\"\n",
        "    from scipy.stats import ttest_ind\n",
        "    \n",
        "    g1 = dataframe1[\"compound_sentiment_score\"]\n",
        "    g2 = dataframe2[\"compound_sentiment_score\"]\n",
        "\n",
        "    # Perform the t-test\n",
        "    t_statistic, p_value = ttest_ind(g1, g2)\n",
        "\n",
        "    return t_statistic, p_value\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentiment t-test statistics for the democrats subreddit: T-statistic: -0.18769776861679455, P-value: 0.8512097164028811\n",
            "Sentiment t-test statistics for the Republican subreddit: T-statistic: 0.4576751932220733, P-value: 0.6476235706301625\n",
            "Sentiment t-test statistics for the PoliticalDiscussion subreddit: T-statistic: -1.5855714800727285, P-value: 0.11424095694942944\n"
          ]
        }
      ],
      "source": [
        "#Now let's perform t-tests on the compound sentiments for the POSTS for each political subreddit\n",
        "\n",
        "dem_post_ttest = ttest(df_before_dem, df_after_dem)\n",
        "\n",
        "rep_post_ttest = ttest(df_before_rep, df_after_rep)\n",
        "\n",
        "PD_post_ttest = ttest(df_before_PD, df_after_PD)\n",
        "\n",
        "print(f\"Sentiment t-test statistics for the democrats subreddit: T-statistic: {dem_post_ttest[0]}, P-value: {dem_post_ttest[1]}\")\n",
        "print(f\"Sentiment t-test statistics for the Republican subreddit: T-statistic: {rep_post_ttest[0]}, P-value: {rep_post_ttest[1]}\")\n",
        "print(f\"Sentiment t-test statistics for the PoliticalDiscussion subreddit: T-statistic: {PD_post_ttest[0]}, P-value: {PD_post_ttest[1]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Now we will make dataframes for the comments and subsequently find their t-statistics\n",
        "\n",
        "df_comment_after = pd.DataFrame()\n",
        "df_comment_before = pd.DataFrame()\n",
        "\n",
        "def before_after_dropout_comment_dataframes(a_comment_dataframe):\n",
        "    \"\"\"\n",
        "    This function creates two new dataframes each respectively containing comments from before and after Biden's dropout announcement\n",
        "    based on his UTC time of dropout we found already.\n",
        "    \"\"\"\n",
        "    global df_comment_after, df_comment_before\n",
        "\n",
        "    df_comment_before = a_comment_dataframe[a_comment_dataframe[\"created_utc\"] < 1721583960].copy()\n",
        "    df_comment_after = a_comment_dataframe[a_comment_dataframe[\"created_utc\"] >= 1721598360].copy()\n",
        "\n",
        "\n",
        "\n",
        "before_after_dropout_comment_dataframes(comments_filtered)\n",
        "\n",
        "\n",
        "df_comment_before_dem = pd.DataFrame()\n",
        "df_comment_after_dem = pd.DataFrame()\n",
        "\n",
        "df_comment_before_rep = pd.DataFrame()\n",
        "df_comment_after_rep = pd.DataFrame()\n",
        "\n",
        "df_comment_before_PD = pd.DataFrame()\n",
        "df_comment_after_PD = pd.DataFrame()\n",
        "\n",
        "\n",
        "def seperate_comments_by_party(before_comment_df, after_comment_df):\n",
        "    \"\"\"\n",
        "    This function creates several new dataframes each respectively containing comments from the corresponding subreddits\n",
        "    \"\"\"\n",
        "    global df_comment_before_dem, df_comment_after_dem, df_comment_before_rep, df_comment_after_rep, df_comment_before_PD, df_comment_after_PD\n",
        "\n",
        "    df_comment_before_dem = before_comment_df[before_comment_df[\"subreddit\"] == \"democrats\"].copy()\n",
        "    df_comment_after_dem = after_comment_df[after_comment_df[\"subreddit\"] == \"democrats\"].copy()\n",
        "\n",
        "    df_comment_before_rep = before_comment_df[before_comment_df[\"subreddit\"] == \"Republican\"].copy()\n",
        "    df_comment_after_rep = after_comment_df[after_comment_df[\"subreddit\"] == \"Republican\"].copy()\n",
        "\n",
        "    df_comment_before_PD = before_comment_df[before_comment_df[\"subreddit\"] == \"PoliticalDiscussion\"].copy()\n",
        "    df_comment_after_PD = after_comment_df[after_comment_df[\"subreddit\"] == \"PoliticalDiscussion\"].copy()\n",
        "\n",
        "seperate_comments_by_party(df_comment_after, df_comment_before)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentiment t-test statistics for the democrats subreddit: T-statistic: 5.262430303507806, P-value: 1.5580719024135326e-07\n",
            "Sentiment t-test statistics for the Republican subreddit: T-statistic: -0.49501670298273087, P-value: 0.6207061448726928\n",
            "Sentiment t-test statistics for the PoliticalDiscussion subreddit: T-statistic: 4.976674121177761, P-value: 6.633847775331306e-07\n"
          ]
        }
      ],
      "source": [
        "#Now we do the t-tests for the comments in each subreddit\n",
        "\n",
        "dem_comment_ttest = ttest(df_comment_before_dem, df_comment_after_dem)\n",
        "\n",
        "rep_comment_ttest = ttest(df_comment_before_rep, df_comment_after_rep)\n",
        "\n",
        "PD_comment_ttest = ttest(df_comment_before_PD, df_comment_after_PD)\n",
        "\n",
        "print(f\"Sentiment t-test statistics for the democrats subreddit: T-statistic: {dem_comment_ttest[0]}, P-value: {dem_comment_ttest[1]}\")\n",
        "print(f\"Sentiment t-test statistics for the Republican subreddit: T-statistic: {rep_comment_ttest[0]}, P-value: {rep_comment_ttest[1]}\")\n",
        "print(f\"Sentiment t-test statistics for the PoliticalDiscussion subreddit: T-statistic: {PD_comment_ttest[0]}, P-value: {PD_comment_ttest[1]}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
